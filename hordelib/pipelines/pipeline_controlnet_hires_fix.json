{
  "3": {
    "inputs": {
      "seed": 123456789,
      "steps": 25,
      "cfg": 7.5,
      "sampler_name": "dpmpp_2m",
      "scheduler": "karras",
      "denoise": 1,
      "model": [
        "47",
        0
      ],
      "positive": [
        "23",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "5",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "sampler"
    }
  },
  "5": {
    "inputs": {
      "width": 512,
      "height": 512,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage",
    "_meta": {
      "title": "empty_latent_image"
    }
  },
  "7": {
    "inputs": {
      "text": "",
      "clip": [
        "47",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "negative_prompt"
    }
  },
  "9": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "52",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "output_image"
    }
  },
  "20": {
    "inputs": {
      "image": "example.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "image_loader"
    }
  },
  "23": {
    "inputs": {
      "strength": 0.8500000000000003,
      "conditioning": [
        "24",
        0
      ],
      "control_net": [
        "33",
        0
      ],
      "image": [
        "34",
        0
      ]
    },
    "class_type": "ControlNetApply",
    "_meta": {
      "title": "controlnet_apply"
    }
  },
  "24": {
    "inputs": {
      "text": "a man walking in the jungle\n\n\n",
      "clip": [
        "47",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "prompt"
    }
  },
  "33": {
    "inputs": {
      "control_net_name": "control_scribble_fp16.safetensors",
      "model": [
        "47",
        0
      ]
    },
    "class_type": "DiffControlNetLoader",
    "_meta": {
      "title": "controlnet_model_loader"
    }
  },
  "34": {
    "inputs": {
      "low_threshold": 100,
      "high_threshold": 200,
      "l2gradient": "disable",
      "image": [
        "20",
        0
      ]
    },
    "class_type": "CannyEdgePreprocessor",
    "_meta": {
      "title": "canny"
    }
  },
  "37": {
    "inputs": {
      "rm_nearest": 0,
      "rm_background": 0,
      "image": [
        "20",
        0
      ]
    },
    "class_type": "LeReS-DepthMapPreprocessor",
    "_meta": {
      "title": "depth"
    }
  },
  "39": {
    "inputs": {
      "image": [
        "20",
        0
      ]
    },
    "class_type": "HEDPreprocessor",
    "_meta": {
      "title": "hed"
    }
  },
  "40": {
    "inputs": {
      "a": 6.283185307179586,
      "bg_threshold": 0.05,
      "image": [
        "20",
        0
      ]
    },
    "class_type": "MiDaS-NormalMapPreprocessor",
    "_meta": {
      "title": "normal"
    }
  },
  "42": {
    "inputs": {
      "detect_hand": "disable",
      "image": [
        "20",
        0
      ]
    },
    "class_type": "OpenposePreprocessor",
    "_meta": {
      "title": "openpose"
    }
  },
  "43": {
    "inputs": {
      "image": [
        "20",
        0
      ]
    },
    "class_type": "SemSegPreprocessor",
    "_meta": {
      "title": "seg"
    }
  },
  "44": {
    "inputs": {
      "image": [
        "20",
        0
      ]
    },
    "class_type": "ScribblePreprocessor",
    "_meta": {
      "title": "scribble"
    }
  },
  "45": {
    "inputs": {
      "image": [
        "20",
        0
      ]
    },
    "class_type": "FakeScribblePreprocessor",
    "_meta": {
      "title": "fakescribble"
    }
  },
  "46": {
    "inputs": {
      "score_threshold": 0.15,
      "dist_threshold": 1,
      "image": [
        "20",
        0
      ]
    },
    "class_type": "M-LSDPreprocessor",
    "_meta": {
      "title": "mlsd"
    }
  },
  "47": {
    "inputs": {
      "ckpt_name": "Deliberate.ckpt"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "model_loader"
    }
  },
  "49": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "width": 768,
      "height": 768,
      "crop": "disabled",
      "samples": [
        "3",
        0
      ]
    },
    "class_type": "LatentUpscale",
    "_meta": {
      "title": "latent_upscale"
    }
  },
  "50": {
    "inputs": {
      "seed": 287046928977701,
      "steps": 15,
      "cfg": 8,
      "sampler_name": "dpmpp_2m",
      "scheduler": "simple",
      "denoise": 0.6,
      "model": [
        "47",
        0
      ],
      "positive": [
        "24",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "49",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "upscale_sampler"
    }
  },
  "52": {
    "inputs": {
      "samples": [
        "50",
        0
      ],
      "vae": [
        "47",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "vae_decode"
    }
  }
}
